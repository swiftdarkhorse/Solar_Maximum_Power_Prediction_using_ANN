# -*- coding: utf-8 -*-
"""BE_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GsU1GFcqFwPjboNeIHkb_5MlaSBI5OdO

Installing Required Libraries for Extracting, Transforming and Loading of Dataset. Also, for building and training the Model
"""

import pandas as pd
import tensorflow as tf
import csv
import numpy as np
import keras
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""Importing a CSV File as a Pandas Dataframe"""

df = pd.read_csv("/content/drive/My Drive/Colab Notebooks/solar_data.csv")

"""Displaying first five entries of the Dataset"""

df.head()

"""Shuffling the data in the Dataset and spliting it into Training set and Test set as specified"""

train, test = train_test_split(df, test_size = 0.1)

"""Displaying first five entries of the Training Dataset"""

train.head()

"""Displaying first five entries of the Testing Dataset"""

test.head()

"""Seperating Inputs and Labels from the Training and Testing Data by converting Pandas Dataframe into Numpy Arrays"""

train = np.array(train)
test = np.array(test)
x_train = np.delete(train, 5, axis = 1)
y_train = train[:,5]
x_test = np.delete(test, 5, axis = 1)
y_test = test[:,5]

"""Converting Numpy arrays into Tensors"""

x_train = x_train.astype(float)
y_train = y_train.astype(float)
x_train = tf.convert_to_tensor(x_train)
y_train = tf.convert_to_tensor(y_train)

"""Building Model with 5 input, 4 hidden and 1 output layer."""

model = tf.keras.models.Sequential([
                                    tf.keras.layers.Dense(units = 4, input_shape = [5]),
                                    tf.keras.layers.Dense(units = 1)
                                   ])

"""Displaying the structure of the Neural Model"""

model.summary()

"""Compiling the Model with appropriate Optimizer and Loss Function"""

model.compile(optimizer='adam',
                  loss='mean_squared_error',
                  )

"""Training the Model on the Training Data"""

history = model.fit(x_train, y_train, epochs = 100, validation_data=(x_test, y_test))

"""Evaluating the Model on the Test Set"""

model.evaluate(x_test,y_test)

"""Displaying the Training and Validation loss over no. of Epochs"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Saving the model as yaml File for reusing"""

from keras.models import model_from_yaml
# serialize model to YAML
model_yaml = model.to_yaml()
with open("model.yaml", "w") as yaml_file:
    yaml_file.write(model_yaml)
# serialize weights to HDF5
model.save_weights("model.h5")
model.load_weights("model.h5")
model.save("model.h5")
print("Saved model to disk")

"""Converting the saved Model to Tensorflow Lite to be loaded on to a Raspberry Pi"""

model_yaml = tf.keras.models.load_model('/content/model.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model_yaml)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)